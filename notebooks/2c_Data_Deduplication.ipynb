{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3c672df3",
   "metadata": {},
   "source": [
    "# 2c. DATA DEDUPLICATION\n",
    "\n",
    "This notebook handles:\n",
    "1. **Exact Duplicate Detection** - Find and remove fully identical rows\n",
    "2. **Near-Duplicate Detection** - Use similarity measures to find non-exact duplicates\n",
    "3. **Similarity Functions** - Implement Jaccard, Levenshtein, and other measures\n",
    "4. **Blocking Strategies** - Efficient candidate generation for large datasets\n",
    "5. **Duplicate Resolution** - Merge or remove identified duplicates"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "695846b2",
   "metadata": {},
   "source": [
    "## 2c.1 Imports and Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e171ffb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "import re\n",
    "\n",
    "pd.set_option('display.max_columns', 50)\n",
    "pd.set_option('display.width', 140)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "498d6f03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the cleaned dataset from previous step\n",
    "try:\n",
    "    MILANO = pd.read_csv(\"MILANO_cleaned.csv\", sep=\";\")\n",
    "    print(\"Loaded cleaned dataset\")\n",
    "except FileNotFoundError:\n",
    "    try:\n",
    "        MILANO = pd.read_csv(\"MILANO_transformed.csv\", sep=\";\")\n",
    "        print(\"Loaded transformed dataset\")\n",
    "    except FileNotFoundError:\n",
    "        MILANO = pd.read_csv(\"Comune-di-Milano-Pubblici-esercizi(in)-2.csv\", sep=\";\")\n",
    "        print(\"Loaded original dataset\")\n",
    "\n",
    "print(f\"Shape: {MILANO.shape}\")\n",
    "MILANO.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c80564b8",
   "metadata": {},
   "source": [
    "---\n",
    "# 1. EXACT DUPLICATE DETECTION"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8cf3504",
   "metadata": {},
   "source": [
    "## 1.1 Find Exact Duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6171d3b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for exact duplicates across all columns\n",
    "duplicates = MILANO.duplicated(keep=False)  # Mark all duplicates including first occurrence\n",
    "n_duplicates = MILANO.duplicated().sum()  # Count of duplicates (excluding first)\n",
    "\n",
    "print(f\"Total rows: {len(MILANO)}\")\n",
    "print(f\"Exact duplicate rows (excluding first): {n_duplicates}\")\n",
    "print(f\"Total rows involved in duplication: {duplicates.sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c085b90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display duplicate rows if any\n",
    "if duplicates.sum() > 0:\n",
    "    print(\"Duplicate rows:\")\n",
    "    display(MILANO[duplicates].sort_values(by=list(MILANO.columns)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09c06802",
   "metadata": {},
   "source": [
    "## 1.2 Check Duplicates on Key Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60a7ac4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check duplicates on address columns (potential business key)\n",
    "address_cols = ['Codice via', 'Civico', 'ZD']\n",
    "available_cols = [c for c in address_cols if c in MILANO.columns]\n",
    "\n",
    "if available_cols:\n",
    "    dups_address = MILANO.duplicated(subset=available_cols, keep=False)\n",
    "    print(f\"Rows with duplicate address ({available_cols}): {dups_address.sum()}\")\n",
    "    \n",
    "    if dups_address.sum() > 0 and dups_address.sum() <= 50:\n",
    "        print(\"\\nSample of duplicate addresses:\")\n",
    "        display(MILANO[dups_address].sort_values(by=available_cols).head(20))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75a30b93",
   "metadata": {},
   "source": [
    "## 1.3 Remove Exact Duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c95bfa8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove exact duplicates (keep first occurrence)\n",
    "before_count = len(MILANO)\n",
    "MILANO = MILANO.drop_duplicates(keep='first')\n",
    "after_count = len(MILANO)\n",
    "\n",
    "print(f\"Rows before: {before_count}\")\n",
    "print(f\"Rows after: {after_count}\")\n",
    "print(f\"Removed: {before_count - after_count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae9835e7",
   "metadata": {},
   "source": [
    "---\n",
    "# 2. SIMILARITY FUNCTIONS\n",
    "\n",
    "Implement various similarity measures for near-duplicate detection."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94ff2939",
   "metadata": {},
   "source": [
    "## 2.1 Jaccard Similarity (Set-based)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4313380d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def jaccard_similarity(s1, s2):\n",
    "    \"\"\"Compute Jaccard similarity between two strings (as sets of tokens).\"\"\"\n",
    "    if pd.isna(s1) or pd.isna(s2):\n",
    "        return 0.0\n",
    "    \n",
    "    set1 = set(str(s1).lower().split())\n",
    "    set2 = set(str(s2).lower().split())\n",
    "    \n",
    "    if len(set1) == 0 and len(set2) == 0:\n",
    "        return 1.0\n",
    "    \n",
    "    intersection = set1.intersection(set2)\n",
    "    union = set1.union(set2)\n",
    "    \n",
    "    return len(intersection) / len(union) if len(union) > 0 else 0.0\n",
    "\n",
    "# Test\n",
    "print(\"Jaccard examples:\")\n",
    "print(f\"  'bar caffè milano' vs 'bar caffe milano': {jaccard_similarity('bar caffè milano', 'bar caffe milano'):.3f}\")\n",
    "print(f\"  'ristorante italiano' vs 'pizzeria italiana': {jaccard_similarity('ristorante italiano', 'pizzeria italiana'):.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7ce809e",
   "metadata": {},
   "source": [
    "## 2.2 Levenshtein Distance (Edit Distance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21a6d535",
   "metadata": {},
   "outputs": [],
   "source": [
    "def levenshtein_distance(s1, s2):\n",
    "    \"\"\"Compute Levenshtein (edit) distance between two strings.\"\"\"\n",
    "    if pd.isna(s1) or pd.isna(s2):\n",
    "        return float('inf')\n",
    "    \n",
    "    s1, s2 = str(s1).lower(), str(s2).lower()\n",
    "    \n",
    "    if len(s1) < len(s2):\n",
    "        s1, s2 = s2, s1\n",
    "    \n",
    "    if len(s2) == 0:\n",
    "        return len(s1)\n",
    "    \n",
    "    previous_row = range(len(s2) + 1)\n",
    "    for i, c1 in enumerate(s1):\n",
    "        current_row = [i + 1]\n",
    "        for j, c2 in enumerate(s2):\n",
    "            insertions = previous_row[j + 1] + 1\n",
    "            deletions = current_row[j] + 1\n",
    "            substitutions = previous_row[j] + (c1 != c2)\n",
    "            current_row.append(min(insertions, deletions, substitutions))\n",
    "        previous_row = current_row\n",
    "    \n",
    "    return previous_row[-1]\n",
    "\n",
    "def levenshtein_similarity(s1, s2):\n",
    "    \"\"\"Compute normalized Levenshtein similarity (0-1 range).\"\"\"\n",
    "    if pd.isna(s1) or pd.isna(s2):\n",
    "        return 0.0\n",
    "    \n",
    "    s1, s2 = str(s1), str(s2)\n",
    "    max_len = max(len(s1), len(s2))\n",
    "    \n",
    "    if max_len == 0:\n",
    "        return 1.0\n",
    "    \n",
    "    distance = levenshtein_distance(s1, s2)\n",
    "    return 1 - (distance / max_len)\n",
    "\n",
    "# Test\n",
    "print(\"Levenshtein examples:\")\n",
    "print(f\"  'caffè' vs 'caffe': distance={levenshtein_distance('caffè', 'caffe')}, similarity={levenshtein_similarity('caffè', 'caffe'):.3f}\")\n",
    "print(f\"  'bar milano' vs 'bar milana': distance={levenshtein_distance('bar milano', 'bar milana')}, similarity={levenshtein_similarity('bar milano', 'bar milana'):.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7afc6e9",
   "metadata": {},
   "source": [
    "## 2.3 Q-Gram Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7cf4642",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_qgrams(s, q=2):\n",
    "    \"\"\"Extract q-grams (character n-grams) from a string.\"\"\"\n",
    "    if pd.isna(s):\n",
    "        return []\n",
    "    s = str(s).lower()\n",
    "    return [s[i:i+q] for i in range(len(s) - q + 1)]\n",
    "\n",
    "def qgram_similarity(s1, s2, q=2):\n",
    "    \"\"\"Compute q-gram similarity using Jaccard on q-grams.\"\"\"\n",
    "    qgrams1 = Counter(get_qgrams(s1, q))\n",
    "    qgrams2 = Counter(get_qgrams(s2, q))\n",
    "    \n",
    "    if len(qgrams1) == 0 and len(qgrams2) == 0:\n",
    "        return 1.0\n",
    "    \n",
    "    intersection = sum((qgrams1 & qgrams2).values())\n",
    "    union = sum((qgrams1 | qgrams2).values())\n",
    "    \n",
    "    return intersection / union if union > 0 else 0.0\n",
    "\n",
    "# Test\n",
    "print(\"Q-gram (2-gram) examples:\")\n",
    "print(f\"  'caffè' -> {get_qgrams('caffè', 2)}\")\n",
    "print(f\"  'caffe' -> {get_qgrams('caffe', 2)}\")\n",
    "print(f\"  Similarity: {qgram_similarity('caffè', 'caffe', 2):.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e696eab",
   "metadata": {},
   "source": [
    "---\n",
    "# 3. NEAR-DUPLICATE DETECTION"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b169dc57",
   "metadata": {},
   "source": [
    "## 3.1 Define Comparison Key\n",
    "\n",
    "We'll look for near-duplicates based on similar business names (`Insegna`) and same address."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6b4522a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a composite key for blocking\n",
    "MILANO['block_key'] = (\n",
    "    MILANO['Codice via'].astype(str) + '_' +\n",
    "    MILANO['Civico'].astype(str)\n",
    ")\n",
    "\n",
    "# Count how many records share the same block key\n",
    "block_sizes = MILANO['block_key'].value_counts()\n",
    "print(f\"Total blocks: {len(block_sizes)}\")\n",
    "print(f\"Blocks with multiple records: {(block_sizes > 1).sum()}\")\n",
    "print(f\"\\nLargest blocks:\")\n",
    "display(block_sizes.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58ff3cfb",
   "metadata": {},
   "source": [
    "## 3.2 Find Near-Duplicates within Blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40e670f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_near_duplicates(df, block_col, compare_col, similarity_threshold=0.8):\n",
    "    \"\"\"Find near-duplicates within each block based on string similarity.\"\"\"\n",
    "    near_dups = []\n",
    "    \n",
    "    # Group by block key\n",
    "    for block_key, group in df.groupby(block_col):\n",
    "        if len(group) < 2:\n",
    "            continue\n",
    "        \n",
    "        indices = group.index.tolist()\n",
    "        \n",
    "        # Compare all pairs within block\n",
    "        for i, idx1 in enumerate(indices):\n",
    "            for idx2 in indices[i+1:]:\n",
    "                val1 = df.loc[idx1, compare_col]\n",
    "                val2 = df.loc[idx2, compare_col]\n",
    "                \n",
    "                sim = levenshtein_similarity(val1, val2)\n",
    "                \n",
    "                if sim >= similarity_threshold:\n",
    "                    near_dups.append({\n",
    "                        'idx1': idx1,\n",
    "                        'idx2': idx2,\n",
    "                        'block': block_key,\n",
    "                        'val1': val1,\n",
    "                        'val2': val2,\n",
    "                        'similarity': sim\n",
    "                    })\n",
    "    \n",
    "    return pd.DataFrame(near_dups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0900bc96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find near-duplicates based on Insegna similarity within same address\n",
    "insegna_col = 'Insegna' if 'Insegna' in MILANO.columns else None\n",
    "\n",
    "if insegna_col:\n",
    "    near_dups = find_near_duplicates(\n",
    "        MILANO,\n",
    "        block_col='block_key',\n",
    "        compare_col=insegna_col,\n",
    "        similarity_threshold=0.7\n",
    "    )\n",
    "    \n",
    "    print(f\"Found {len(near_dups)} potential near-duplicate pairs\")\n",
    "    \n",
    "    if len(near_dups) > 0:\n",
    "        display(near_dups.sort_values('similarity', ascending=False).head(20))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea5f2639",
   "metadata": {},
   "source": [
    "## 3.3 Examine Near-Duplicate Candidates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abe0a61a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show full records for top near-duplicate pairs\n",
    "if insegna_col and len(near_dups) > 0:\n",
    "    top_pairs = near_dups.sort_values('similarity', ascending=False).head(5)\n",
    "    \n",
    "    for _, pair in top_pairs.iterrows():\n",
    "        print(f\"\\n=== Similarity: {pair['similarity']:.3f} ===\")\n",
    "        print(f\"Block: {pair['block']}\")\n",
    "        \n",
    "        display(MILANO.loc[[pair['idx1'], pair['idx2']]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4da3e61",
   "metadata": {},
   "source": [
    "---\n",
    "# 4. BLOCKING STRATEGIES"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d77e4ef5",
   "metadata": {},
   "source": [
    "## 4.1 Standard Blocking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03abb0b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Blocking by Zone (ZD)\n",
    "if 'ZD' in MILANO.columns:\n",
    "    zone_blocks = MILANO.groupby('ZD').size()\n",
    "    print(\"Records per Zone (ZD):\")\n",
    "    display(zone_blocks)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3bb978b",
   "metadata": {},
   "source": [
    "## 4.2 Sorted Neighborhood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f23c33c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sorted_neighborhood_pairs(df, sort_col, window_size=3):\n",
    "    \"\"\"Generate candidate pairs using sorted neighborhood method.\"\"\"\n",
    "    # Sort by the specified column\n",
    "    sorted_df = df.sort_values(sort_col).reset_index()\n",
    "    \n",
    "    pairs = []\n",
    "    for i in range(len(sorted_df)):\n",
    "        for j in range(i + 1, min(i + window_size, len(sorted_df))):\n",
    "            pairs.append({\n",
    "                'idx1': sorted_df.loc[i, 'index'],\n",
    "                'idx2': sorted_df.loc[j, 'index'],\n",
    "                'val1': sorted_df.loc[i, sort_col],\n",
    "                'val2': sorted_df.loc[j, sort_col]\n",
    "            })\n",
    "    \n",
    "    return pd.DataFrame(pairs)\n",
    "\n",
    "# Example with street code\n",
    "if 'Codice via' in MILANO.columns:\n",
    "    # Use on a sample for demonstration\n",
    "    sample = MILANO.head(100)\n",
    "    sn_pairs = sorted_neighborhood_pairs(sample, 'Codice via', window_size=3)\n",
    "    print(f\"Sorted neighborhood candidates (sample): {len(sn_pairs)} pairs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "606f50ec",
   "metadata": {},
   "source": [
    "---\n",
    "# 5. DUPLICATE RESOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "084f209b",
   "metadata": {},
   "source": [
    "## 5.1 Merge Strategy for Duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f125b59",
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_duplicates(df, dup_pairs, prefer='first'):\n",
    "    \"\"\"Mark duplicates for removal, keeping preferred record.\"\"\"\n",
    "    to_remove = set()\n",
    "    \n",
    "    for _, pair in dup_pairs.iterrows():\n",
    "        if prefer == 'first':\n",
    "            to_remove.add(pair['idx2'])\n",
    "        else:\n",
    "            to_remove.add(pair['idx1'])\n",
    "    \n",
    "    return list(to_remove)\n",
    "\n",
    "# If we have near-duplicates to handle\n",
    "if insegna_col and len(near_dups) > 0:\n",
    "    # Only consider high-confidence matches (>= 0.9 similarity)\n",
    "    high_conf_dups = near_dups[near_dups['similarity'] >= 0.9]\n",
    "    \n",
    "    if len(high_conf_dups) > 0:\n",
    "        indices_to_remove = merge_duplicates(MILANO, high_conf_dups, prefer='first')\n",
    "        print(f\"Indices marked for removal: {len(indices_to_remove)}\")\n",
    "        print(f\"Indices: {indices_to_remove[:10]}...\") if len(indices_to_remove) > 10 else print(f\"Indices: {indices_to_remove}\")\n",
    "    else:\n",
    "        print(\"No high-confidence duplicates to remove\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b7a0980",
   "metadata": {},
   "source": [
    "## 5.2 Summary of Deduplication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aab11aa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean up temporary columns\n",
    "if 'block_key' in MILANO.columns:\n",
    "    MILANO = MILANO.drop(columns=['block_key'])\n",
    "\n",
    "print(\"=== DEDUPLICATION SUMMARY ===\")\n",
    "print(f\"Final row count: {len(MILANO)}\")\n",
    "print(f\"Exact duplicates removed: Yes\")\n",
    "print(f\"Near-duplicates identified: {len(near_dups) if 'near_dups' in dir() else 0}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81ee72b1",
   "metadata": {},
   "source": [
    "---\n",
    "# 6. SAVE DEDUPLICATED DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92e4a77d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the deduplicated dataset\n",
    "MILANO.to_csv(\"MILANO_deduplicated.csv\", index=False, sep=\";\")\n",
    "print(\"Saved: MILANO_deduplicated.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81f9f8c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final preview\n",
    "print(f\"Final dataset shape: {MILANO.shape}\")\n",
    "MILANO.head()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
